{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Chaitanya\\\\Documents\\\\ML\\\\Indian-Medical-Leaf-Clf\\\\Medicinal-Leaf-Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Chaitanya\\\\Documents\\\\ML\\\\Indian-Medical-Leaf-Clf\\\\Medicinal-Leaf-Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entity (config_entity.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path  \n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_image_size: list\n",
    "    params_is_augmentation: bool\n",
    "    params_seed: int\n",
    "\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congiguration (configuration.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MedicineLeafClassifier.constants import *\n",
    "from MedicineLeafClassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH  ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    \n",
    "    def get_prepare_callbacks_config(self) -> PrepareCallbacksConfig:\n",
    "\n",
    "        config = self.config.prepare_callbacks\n",
    "            \n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callbacks_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callbacks_config\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"indian-medicinal-leaf-image-dataset\",\"Medicinal Leaf dataset\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        trainig_config = TrainingConfig(\n",
    "            root_dir = Path(training.root_dir),\n",
    "            trained_model_path = Path(training.trained_model_path),\n",
    "            updated_base_model_path = Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data = Path(training_data),\n",
    "            params_epochs = params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_seed = params.SEED\n",
    "        )\n",
    "\n",
    "        return trainig_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components (training.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareCallback:\n",
    "    def __init__(self,config:PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def create_tb_callback(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f\"tb_logs_at_{timestamp}\",\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir = tb_running_log_dir)\n",
    "    @property\n",
    "    def create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(self.config.checkpoint_model_filepath,\"model_{epoch}.h5\"),  # Replace with your desired path\n",
    "            save_best_only=True,  # Set to True to save only the best model based on a metric\n",
    "            monitor='val_accuracy',  # Monitor validation accuracy during training\n",
    "            save_weights_only=False,  # Set to True to save only model weights\n",
    "            verbose=1  # Set to 0 for silent operation\n",
    "        )\n",
    "    @property\n",
    "    def create_early_stopping(self):\n",
    "        return tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',  # Monitor validation accuracy\n",
    "            min_delta=0.01,  # Minimum required change in the monitored metric\n",
    "            patience=50,  # Number of epochs with no improvement to wait before stopping\n",
    "            baseline = 0.5,\n",
    "            restore_best_weights=True  # Restore the weights of the best model before stopping\n",
    "        )\n",
    "    @property\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self.create_tb_callback,\n",
    "            self.create_ckpt_callbacks,\n",
    "            self.create_early_stopping\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self,config: TrainingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "    \n",
    "    def train_valid_split(self):\n",
    "        self.train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "             self.config.training_data,\n",
    "             labels = 'inferred',\n",
    "             label_mode = 'int',\n",
    "             color_mode = 'rgb',\n",
    "            class_names = None,\n",
    "             batch_size = self.config.params_batch_size,\n",
    "             image_size= (self.config.params_image_size[0], self.config.params_image_size[1]),\n",
    "             shuffle=True,\n",
    "             seed=self.config.params_seed,\n",
    "             validation_split=0.1,\n",
    "             subset='training',\n",
    "             )\n",
    "        \n",
    "        self.valid_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "             self.config.training_data,\n",
    "             labels = 'inferred',\n",
    "             label_mode = 'int',\n",
    "             color_mode = 'rgb',\n",
    "            class_names = None,\n",
    "             batch_size = self.config.params_batch_size,\n",
    "             image_size= (self.config.params_image_size[0], self.config.params_image_size[1]),\n",
    "             shuffle=True,\n",
    "             seed=self.config.params_seed,\n",
    "             validation_split=0.1,\n",
    "             subset='validation',\n",
    "             )\n",
    "        \n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "        self.train_data = self.train_data.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "        self.valid_data = self.valid_data.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "        # return train_data, valid_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model = tf.keras.Model):\n",
    "        \"\"\" Saves the model after last epoch\n",
    "          irrespective of best accuracy or not \"\"\"\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "    def train(self, callbacks_list: list):\n",
    "        self.model.fit(\n",
    "            self.train_data,\n",
    "            epochs = self.config.params_epochs,\n",
    "            \n",
    "            validation_data = self.valid_data,\n",
    "            \n",
    "            callbacks = callbacks_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path = self.config.trained_model_path,\n",
    "             model = self.model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-03 08:37:29,935: INFO: parameter_server_strategy: ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "[2024-03-03 08:37:29,962: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-03 08:37:29,980: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-03 08:37:29,986: INFO: common: Created directory at artifacts]\n",
      "[2024-03-03 08:37:29,988: INFO: common: Created directory at artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2024-03-03 08:37:29,990: INFO: common: Created directory at artifacts\\prepare_callbacks\\tensorboard_log_dir]\n",
      "[2024-03-03 08:37:29,994: INFO: common: Created directory at artifacts\\training]\n",
      "Found 6900 files belonging to 80 classes.\n",
      "Using 6210 files for training.\n",
      "Found 6900 files belonging to 80 classes.\n",
      "Using 690 files for validation.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/inception_resnet_v2/batch_normalization_28/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\threading.py\", line 966, in _bootstrap\n      self._bootstrap_inner()\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\threading.py\", line 1009, in _bootstrap_inner\n      self.run()\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'sequential/inception_resnet_v2/batch_normalization_28/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,48,25,25] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/inception_resnet_v2/batch_normalization_28/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_41972]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     training\u001b[38;5;241m.\u001b[39mtrain(callbacks_list\u001b[38;5;241m=\u001b[39mcallbacks_list)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     training\u001b[38;5;241m.\u001b[39mget_base_model()\n\u001b[0;32m     20\u001b[0m     training\u001b[38;5;241m.\u001b[39mtrain_valid_split()\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[10], line 55\u001b[0m, in \u001b[0;36mTraining.train\u001b[1;34m(self, callbacks_list)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks_list: \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(\n\u001b[0;32m     65\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrained_model_path,\n\u001b[0;32m     66\u001b[0m          model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel )\n",
      "File \u001b[1;32mc:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/inception_resnet_v2/batch_normalization_28/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\threading.py\", line 966, in _bootstrap\n      self._bootstrap_inner()\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\threading.py\", line 1009, in _bootstrap_inner\n      self.run()\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\Chaitanya\\Anaconda3\\envs\\IMLD_clf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'sequential/inception_resnet_v2/batch_normalization_28/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,48,25,25] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/inception_resnet_v2/batch_normalization_28/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_41972]"
     ]
    }
   ],
   "source": [
    "device = tf.config.list_physical_devices(\"GPU\")\n",
    "if device:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(device[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "stratergy = tf.distribute.experimental.CentralStorageStrategy()\n",
    "with stratergy.scope():\n",
    "\n",
    "    try:\n",
    "        config = ConfigurationManager()\n",
    "        prepare_callbacks_config = config.get_prepare_callbacks_config()  \n",
    "        prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "        callbacks_list = prepare_callbacks.get_tb_ckpt_callbacks\n",
    "\n",
    "        training_config = config.get_training_config()\n",
    "        training = Training(config=training_config)\n",
    "        training.get_base_model()\n",
    "        training.train_valid_split()\n",
    "        training.train(callbacks_list=callbacks_list)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMLD_clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
